---
name: spec-verification
description: Use during Phase 5 of spec creation to verify completeness and accuracy before implementation - checks requirements accuracy, visual integration, reusability leverage, task specificity, and identifies over-engineering concerns
---

# Spec Verification

## What It Does

Verifies specification through systematic checks:
1. Requirements accuracy (vs original Q&A)
2. Visual asset integration
3. Reusability opportunities leveraged
4. Task specificity and traceability
5. Over-engineering concerns
6. Creates verification report with findings

**Pass = ready for implementation. Fail = fix issues first.**

## The Process

### Step 1: Load All Documentation

```bash
SPEC="[provided by workflow]"

cat "$SPEC/planning/initialization.md"
cat "$SPEC/planning/requirements.md"
cat "$SPEC/spec.md"
cat "$SPEC/tasks.md"
ls -la "$SPEC/planning/visuals/"
```

Keep original Q&A from requirements gathering in memory.

### Step 2: Run Verification Checks

#### Check 1: Requirements Accuracy

Compare requirements.md against original Q&A:

```
âœ“ All questions documented
âœ“ All answers captured exactly
âœ“ Follow-ups included
âœ“ Reusability opportunities documented

Flag:
âœ— Missing answers
âœ— Modified answers (should be exact)
âœ— Missing follow-ups
```

#### Check 2: Visual Assets

```bash
VISUALS=$(ls "$SPEC/planning/visuals/" 2>/dev/null)

if [ ! -z "$VISUALS" ]; then
  # Read each visual
  # Check requirements.md mentions them
  grep -q "Visual Assets" "$SPEC/planning/requirements.md"
fi
```

**If visuals exist, verify:**
```
âœ“ Mentioned in requirements.md
âœ“ Design elements in spec.md
âœ“ Tasks reference visual files
âœ“ Fidelity level noted

Flag:
âœ— Visuals not in requirements
âœ— Elements missing from spec
âœ— Tasks don't reference mockups
```

#### Check 3: Visual Design Analysis

**Only if visuals exist** - Read each file:

```
For each visual:
1. Identify components (header, sidebar, cards, forms)
2. Note layout structure
3. Observe colors/typography (if high-fi)
4. Document interactive elements

Then verify:
âœ“ Visual Design section exists in spec.md
âœ“ Each file has description
âœ“ Key components mentioned
âœ“ Layout captured

And in tasks.md:
âœ“ Frontend tasks reference visual files
âœ“ Tasks mention building shown components
```

#### Check 4: Requirements Coverage

From requirements.md, build checklist:

**Explicit features:**
- [Feature A]
- [Feature B]

**Check spec.md:**
```
âœ“ Each feature has requirement
âœ— Missing features
âœ— Added features (not in requirements)
âœ— Changed scope
```

**Reusability opportunities:**
```
User mentioned:
- [Similar feature/path]

Check spec.md "Existing Code to Leverage":
âœ“ User-mentioned features referenced
âœ“ Paths documented
âœ— Opportunities ignored
```

**Out of scope:**
```
User said NOT to include:
- [Item A]

Check spec.md "Out of Scope":
âœ“ All exclusions listed
âœ— Missing exclusions
âœ— Excluded items in requirements
```

#### Check 5: Spec Structure

```
âœ“ Goal section (1-2 sentences)
âœ“ User Stories (2-3 stories)
âœ“ Specific Requirements
âœ“ Visual Design (if visuals exist)
âœ“ Existing Code to Leverage
âœ“ Out of Scope

Flag:
âœ— Extra sections (violates template)
âœ— Missing required sections
âœ— Vague requirements
âœ— Ignoring reusability
```

#### Check 6: Task List Validation

**Task specificity:**
```
âœ“ Each task references specific component
âœ“ Traceable to spec requirements
âœ“ Clear acceptance criteria

Flag:
âœ— Vague tasks ("add validation")
âœ— Tasks not in requirements
âœ— Missing visual references (if visuals exist)
```

**Reusability references:**
```
âœ“ Tasks note "(reuse: [name])" where applicable

Flag:
âœ— Tasks recreate existing components
âœ— Missing reuse notes
```

**Task count per group:**
```
âœ“ 3-10 tasks per group

Flag:
âœ— More than 10 (possibly over-engineered)
âœ— Fewer than 3 (possibly too broad)
```

#### Check 7: Over-Engineering

```
Flag unnecessary complexity:
âœ— New component when existing works
âœ— Duplicating existing logic
âœ— Features beyond requirements
âœ— Premature optimization
âœ— Unnecessary abstractions
```

### Step 3: Create Verification Report

```bash
mkdir -p "$SPEC/verification"

cat > "$SPEC/verification/spec-verification.md" <<'EOF'
# Specification Verification Report

## Summary
- **Status:** [âœ… Passed / âš ï¸ Issues / âŒ Failed]
- **Date:** [Current date]
- **Spec:** [Spec name]
- **Reusability:** [âœ… Passed / âš ï¸ Concerns / âŒ Failed]

## Structural Verification

### Check 1: Requirements Accuracy
[Findings]

### Check 2: Visual Assets
[Findings]

## Content Validation

### Check 3: Visual Design Tracking
[If visuals exist - each visual's tracking]

### Check 4: Requirements Coverage

**Explicit Features:**
- Feature A: [âœ… Covered / âŒ Missing]

**Reusability:**
- [Feature] at [path]: [âœ… Referenced / âš ï¸ Not leveraged]

**Out of Scope:**
- Correctly excluded: [list]
- Issues: [list if any]

### Check 5: Spec Structure
[Findings]

### Check 6: Task List
[Findings on specificity, reusability, visual references]

### Check 7: Over-Engineering
[Any unnecessary complexity identified]

## Issues Summary

### Critical Issues (MUST fix)
1. [Issue]

### Important Issues (Should fix)
1. [Issue]

### Minor Issues (Optional)
1. [Issue]

### Over-Engineering Concerns
1. [Issue]

## Recommendations
1. [Specific recommendation]

## Conclusion
[Assessment with guidance]

[If passed:]
Spec complete, accurate, ready for implementation.

[If issues:]
Address [X] critical and [Y] important issues before implementation.
EOF
```

### Step 4: Present Results

**If PASSED:**
```
âœ… Specification Verification PASSED

Checks completed:
âœ… Requirements accurate
âœ… Visuals integrated ([X] files)
âœ… Reusability leveraged
âœ… Tasks specific and traceable
âœ… No over-engineering

Report: verification/spec-verification.md

ðŸŽ‰ Spec ready for implementation!

What next?
1. Start implementation
2. Review report
3. Optional improvements
4. Return to /catchup
```

**If ISSUES:**
```
âš ï¸  Specification Verification Found Issues

Status: [âš ï¸ Issues / âŒ Failed]

Summary:
- Critical: [X] (MUST fix)
- Important: [Y] (Should fix)
- Minor: [Z] (Optional)
- Over-engineering: [A]

Critical:
1. [Brief description]

Report: verification/spec-verification.md

Options:
1. Review full report
2. Fix automatically
3. Fix specific issues
4. I'll fix manually

What next?
```

**WAIT for choice.**

### Step 5: Handle Issues

**If automatic fix:**

For each critical/important:
1. Identify affected file
2. Determine fix
3. Apply fix
4. Show change
5. Continue

**After fixes:**
```
Applied fixes:
âœ… [Issue 1] - [Change]

Re-running verification...
```

**Re-run from Step 2.**

**If specific fixes:**
- User specifies issues
- Fix those
- Re-verify

**If manual:**
- Provide guidance
- Return to workflow

## Red Flags

**Never:**
- Skip visual analysis if files exist
- Approve with critical issues
- Ignore reusability opportunities
- Allow feature creep

**Always:**
- Run bash to verify visuals
- Read and analyze visual files
- Verify reusability leveraged
- Distinguish issue severity

## Integration

**Called by:**
- `spec-creation-workflow` (Phase 5)

**Returns to:**
- `spec-creation-workflow` with status

**Creates:**
- `[spec]/verification/spec-verification.md`

**May trigger:**
- Re-execution of Phases 2-4 to fix issues

**Next if passed:**
- Ready for `spec-implementation-workflow`
